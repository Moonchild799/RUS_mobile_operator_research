{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оглавление\n",
    "- [Вступление](#intro)\n",
    "- [Общая информация](#general_info)\n",
    "- [Разбитие по выборкам](#splitting)\n",
    "- [Исследование моделей](#exploring)\n",
    "  - [Древо решения](#tree)\n",
    "  - [Случайный лес](#forest)\n",
    "  - [Логистическая регрессия](#log_regression)\n",
    "  - [Выводы по исследованию](#exploring_conclusions)\n",
    "- [Проверка на тестовой выборке](#test)\n",
    "- [Проверка на адекватность](#sanity_check)\n",
    "- [Вывод](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## Вступление \n",
    "Оператор мобильной связи «Мегалайн» выяснил: многие клиенты пользуются архивными тарифами. Они хотят построить систему, способную проанализировать поведение клиентов и предложить пользователям новый тариф: «Смарт» или «Ультра».\n",
    "\n",
    "Имеем в наличии данные предоставленные оператором мобильной связи \"Мегалайн\" включающие в себя пользователей которые перешли на новые тарифные планы \"Смарт\" и \"Ультра\". На основе этих данных создадим модель машинного обучения которая поможет таргетировать рекомендации о переходе на новые тарифы для пользователей которые пользуются архивными тарифами.\n",
    "\n",
    "Перед нами стоит задача получить accuracy не менее 0.75 на тестовой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='general_info'></a>\n",
    "## Откройте и изучите файл"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Импортируем необходимые библиотеки**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Читаем исходный файл**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_csv('users_behavior.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Основная информация о датафрейме**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "users.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_ultra\n",
       "0    69.352831\n",
       "1    30.647169\n",
       "Name: is_ultra, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.groupby('is_ultra')['is_ultra'].agg('count') / len(users) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В предоставленных данных есть сведения о 3214 пользователей пользующихся новыми тарифными планами. Данные уже предобработаны, поэтому можем приступать к разборке их на выборки. 69% пользователей используют тарифный план \"Смарт\" и 31% - \"Ультра\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='splitting'></a>\n",
    "## Разобьём данные на выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как это все данные что у нас есть в наличии, нам нужно разбить их на три выборки:\n",
    "- **Тренировачная**: нужна для обучения модели\n",
    "- **Валидационная**: поможет выявить переобучение модели\n",
    "- **Тестовая**: нужна для оценки готовой модели\n",
    "\n",
    "Поделим в соотношении 3:1:1, тоесть 60% - тренировочная выборка и по 20% валидационная и тестовая выборки.\n",
    "\n",
    "Определим целевой признак и признаки. Целевой признак в данном датасете выберем столбец `is_ultra` содержащий информацию о том каким тарифом пользуется пользователь, \"Смарт\" (значение 0) или \"Ультра\" (значение 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = users.drop('is_ultra', axis=1,)\n",
    "target = users['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнём разибивать данные на выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_rest, target_train, target_rest = train_test_split(\n",
    "    features, target, train_size=0.6, random_state=12345, stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1928, 4)\n",
      "(1286, 4)\n",
      "(1928,)\n",
      "(1286,)\n"
     ]
    }
   ],
   "source": [
    "print(features_train.shape)\n",
    "print(features_rest.shape)\n",
    "print(target_train.shape)\n",
    "print(target_rest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбили датасет на две части - тренировочная выборка и остальные данные. Проверили размеры после разибивки, разибка выполнена корректно. Теперь остальные разобьём пополам и получим наши валидационные и тестовые выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_valid, features_test, target_valid, target_test = train_test_split(\n",
    "    features_rest, target_rest, test_size=0.5, random_state=12345, stratify=target_rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(643, 4)\n",
      "(643, 4)\n",
      "(643,)\n",
      "(643,)\n"
     ]
    }
   ],
   "source": [
    "print(features_valid.shape)\n",
    "print(features_test.shape)\n",
    "print(target_valid.shape)\n",
    "print(target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получили валидационные и тестовые выборки, проверили размеры, разбивка выполнена правильно. После нахождения лучших гиперпараметров можем обучить полученную модель используя тренировочную+валидационную выборки, для этого склеим эти выборки для такой ситуации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_val = pd.concat([features_train, features_valid])\n",
    "target_train_val = pd.concat([target_train, target_valid])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем ещё одну разбивку. Будем использовать кросс-валидацию для нахождения лучших гиперпараметров, нам не нужно делать заранее валидационную выборку, поэтому сделаем разбивку на две части: тренировочные данные(75%) и тестовые(25%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_cv_train, features_cv_test, target_cv_train, target_cv_test = train_test_split(\n",
    "    features, target, test_size=0.25, random_state=12345, stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2410, 4)\n",
      "(804, 4)\n",
      "(2410,)\n",
      "(804,)\n"
     ]
    }
   ],
   "source": [
    "print(features_cv_train.shape)\n",
    "print(features_cv_test.shape)\n",
    "print(target_cv_train.shape)\n",
    "print(target_cv_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбивка выполнена правильно. Можем приступать к исследованию моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exploring'></a>\n",
    "## Исследуем модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Целевой признак категориальный, поэтому будем стоить модели классификации. Построим следующие модели: дерево решения, случайный лес и логистическую регрессию. И впоследствии выберем лучшую из них.\n",
    "<a id='tree'></a>\n",
    "### Древо решения \n",
    "\n",
    "С помощью цикла переберем различные гиперпараметры, обучим модель на тренировочных данных и оценим качество на валидацинной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество лучшей модели на валидационной выборке: 0.8087091757387247\n",
      "Лучшая модель: DecisionTreeClassifier(max_depth=8, max_leaf_nodes=42, min_samples_leaf=7,\n",
      "                       random_state=12345)\n",
      "CPU times: user 2min 11s, sys: 300 ms, total: 2min 11s\n",
      "Wall time: 2min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "best_tree_model = None\n",
    "best_tree_result = 0\n",
    "for depth in range(1, 11):\n",
    "    for leafs in range(2, 51):\n",
    "        for samp_leafs in range(1, 51):\n",
    "            model = DecisionTreeClassifier(random_state=12345,\n",
    "                                           max_depth=depth,\n",
    "                                           max_leaf_nodes,\n",
    "                                           min_samples_leaf=samp_leafs)\n",
    "            model.fit(features_train, target_train)\n",
    "            result = model.score(features_valid, target_valid)\n",
    "            if result > best_tree_result:\n",
    "                best_tree_model = model\n",
    "                best_tree_result = result\n",
    "\n",
    "print(\"Качество лучшей модели на валидационной выборке:\", best_tree_result)\n",
    "print(\"Лучшая модель:\", best_tree_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучший результат на валидационной сборке, **качество - 0.809**, показала модель со следующими гиперпараметрами:\n",
    "- max_depth = 8\n",
    "- max_leaf_nodes=42\n",
    "- min_samples_leaf=7\n",
    "- random_state задали для того чтобы зафиксировать псевдослучайность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='forest'></a>\n",
    "### Случайный лес\n",
    "\n",
    "С помощью цикла переберем различные гиперпараметры, обучим модель на тренировочных данных и оценим качество на валидацинной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество лучшей модели на валидационной выборке: 0.8211508553654744\n",
      "Лучшая модель: RandomForestClassifier(max_depth=9, n_estimators=40, random_state=12345)\n",
      "CPU times: user 28.5 s, sys: 156 ms, total: 28.7 s\n",
      "Wall time: 28.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "best_forest_model = None\n",
    "best_forest_result = 0\n",
    "for est in range(10, 151, 10):\n",
    "    for depth in range(1, 11):\n",
    "        model = RandomForestClassifier(random_state=12345,\n",
    "                                       n_estimators=est,\n",
    "                                       max_depth=depth)\n",
    "        model.fit(features_train, target_train)\n",
    "        result = model.score(features_valid, target_valid)\n",
    "        if result > best_forest_result:\n",
    "            best_forest_model = model\n",
    "            best_forest_result = result\n",
    "\n",
    "print(\"Качество лучшей модели на валидационной выборке:\", best_forest_result)\n",
    "print(\"Лучшая модель:\", best_forest_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучший результат на валидационной сборке, **качество - 0.821**, показала модель со следующими гиперпараметрами:\n",
    "- max_depth = 9\n",
    "- n_estimators = 40\n",
    "- random_state задали для того чтобы зафиксировать псевдослучайность\n",
    "\n",
    "Пробовали добавлять в цикл перебор следущие гиперпараметры max_leaf_nodes, min_samples_leaf. Подбор гиперпаметров занимал намного больше времени и результат в большинстве случаев был хуже, поэтому их оставили по умолчанию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем использовать кросс-валидацию GridSearchCV из библиотеки sklearn для нахождения лучших гиперпараметров для случайного леса. Сначала подготовим гиперпараметры которые мы хотим перебрать. Создадим пустые списки и заполним их с помощью циклов значениями которые будем перебирать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = []\n",
    "max_depth = []\n",
    "\n",
    "for est in range(10, 151, 10):\n",
    "    n_estimators.append(est)\n",
    "for depth in range(1, 11):\n",
    "    max_depth.append(depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь укажем какую модель и какие параметры мы будем загружать в GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier()\n",
    "params = {\n",
    "    'random_state': [12345],\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_depth': max_depth\n",
    "         }\n",
    "\n",
    "forest_clf = GridSearchCV(\n",
    "    estimator=forest,\n",
    "    param_grid=params,\n",
    "    cv=5,\n",
    "    scoring='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можем приступать к обучению модели, для GridSearchCV используем данные которые специально для этого разбивали."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 21s, sys: 876 ms, total: 2min 22s\n",
      "Wall time: 2min 22s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
       "                         'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90,\n",
       "                                          100, 110, 120, 130, 140, 150],\n",
       "                         'random_state': [12345]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "forest_clf.fit(features_cv_train, target_cv_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на лучшую модель после проверки кросс-валидацией."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=8, n_estimators=10, random_state=12345)\n",
      "Качество модели: 0.8024896265560166\n"
     ]
    }
   ],
   "source": [
    "print(forest_clf.best_estimator_)\n",
    "print(\"Качество модели:\", forest_clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получили **качество модели: 0.802**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='log_regression'></a>\n",
    "### Логистическая регрессия \n",
    "\n",
    "Попробуем различные гиперпараметры, у логистической регрессии малое количество гиперпараметров и переобучение модели ей не грозит. Обучим модель на тренировочных данных и оценим качество на валидацинной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7387247278382582"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_model = LogisticRegression(random_state=12345, solver='lbfgs', max_iter=1000, multi_class='ovr')\n",
    "log_reg_model.fit(features_train, target_train)\n",
    "log_reg_model.score(features_valid, target_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучший результат на валидационной сборке, **качество - 0.756**, показала модель со следующими гиперпараметрами:\n",
    "- solver = 'lbfgs'\n",
    "- max_iter = 1000\n",
    "- multi_class='ovr'\n",
    "- random_state задали для того чтобы зафиксировать псевдослучайность\n",
    "\n",
    "Пробовали изменять solver на  другие варианты такие как 'newton-cg', 'liblinear', 'sag', 'saga', но 'lbfgs' показал себя лучше всех. Больше всего на результат повлияло указание гиперпараметра multi_class. При попытках использовать 'multinomial' результат был хуже чем 'ovr'.\n",
    "<a id='exploring_conclusions'></a>\n",
    "### Выводы по исследованию моделей \n",
    "\n",
    "Построили следующие модели классификации: Древо Решений, Случайный Лес и Логистическую Регрессию. Обучили их на тренировочных данных. Пробовали различные гиперпараметры:\n",
    "- Для древа решений сделали цикл с помощью которого перебирали следующие гиперпараметры: max_depth, max_leaf_nodes, min_samples_leaf. Результат работы модели оценивали на валидационной выборке с помощью метрики качества accuracy. Таким образом удалось достичь **accuracy - 0.809**.\n",
    "- Для случайного леса сделали цикл с помощью которого перебирали следующие гиперпараметры: max_depth, n_estimators. Пробовали так же изменять max_leaf_nodes и min_samples_leaf, но результат при оставлении их по умолчанию лучше. Таким образом удалось достичь **accuracy - 0.821**. Так же попробовали использовать кросс-валидацию, разбивка данных происходила по другому поэтому полученную **метрику качества 0.802** нет смысла сравнивать с другими, построенными тут моделями.\n",
    "- У логистической мало гиперпараметров которыми мы может повлиять на результат, лучший результат удалось достить указав multi_class='ovr'. **Accuracy** такой модели - **0.739**\n",
    "\n",
    "**Лучшая модель - Случайный Лес, accuracy - 0.821 на валидационной выборке.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='test'></a>\n",
    "## Проверим модель на тестовой выборке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дообучим нашу лучшую модель на тренировочной + валидационной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=9, n_estimators=40, random_state=12345)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_forest_model.fit(features_train_val, target_train_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим как эта модель поведёт себя на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8289269051321928"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_forest_model.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На тестовой выборке accuracy лучше, **0.829** против 0.821 на валидационной."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы ранее строили модель используя кросс-валидацию, проверим её на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8121890547263682"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_clf.score(features_cv_test, target_cv_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат **0.812**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы по тестовой выборке\n",
    "\n",
    "Проверили лучшую модель на тестовой выборке. **Accuracy 0.829** нас устраивает. Теперь проверим модель на адекватность."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sanity_check'></a>\n",
    "## Проверим модели на адекватность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним нашу лучшую модель с \"глупой\" моделью которая будет игнорировать входящие признаки и делать предсказание случайным образом.\n",
    "Попробуем два варианта гиперпараметра strategy у этой модели - most_frequent и stratified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тренировочная выборка: 0.6934647302904564\n",
      "Валидационная выборка: 0.6936236391912908\n",
      "Тестовая выборка: 0.6936236391912908\n"
     ]
    }
   ],
   "source": [
    "dummy = DummyClassifier(random_state=12345, strategy=\"most_frequent\")\n",
    "dummy.fit(features_train, target_train)\n",
    "print('Тренировочная выборка:', dummy.score(features_train, target_train))\n",
    "print('Валидационная выборка:', dummy.score(features_valid, target_valid))\n",
    "print('Тестовая выборка:', dummy.score(features_test, target_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тренировочная выборка: 0.5809128630705395\n",
      "Валидационная выборка: 0.5598755832037325\n",
      "Тестовая выборка: 0.5567651632970451\n"
     ]
    }
   ],
   "source": [
    "dummy = DummyClassifier(random_state=12345, strategy=\"stratified\")\n",
    "dummy.fit(features_train, target_train)\n",
    "print('Тренировочная выборка:', dummy.score(features_train, target_train))\n",
    "print('Валидационная выборка:', dummy.score(features_valid, target_valid))\n",
    "print('Тестовая выборка:', dummy.score(features_test, target_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь посмотрим посмотрим на нашу лучшую модель на трех выборках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тренировочная выборка: 0.8724066390041494\n",
      "Валидационная выборка: 0.8880248833592534\n",
      "Тестовая выборка: 0.8289269051321928\n"
     ]
    }
   ],
   "source": [
    "print('Тренировочная выборка:', best_forest_model.score(features_train, target_train))\n",
    "print('Валидационная выборка:', best_forest_model.score(features_valid, target_valid))\n",
    "print('Тестовая выборка:', best_forest_model.score(features_test, target_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На всех выборках случайный лес показал значительно лучшие результаты чем случайная модель. Можем сделать вывод что модель адекватна."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conclusion'></a>\n",
    "## Вывод \n",
    "\n",
    "Перед нами стояла задача классификации с известным целевым признаком. Исследовали три модели: древо решения, случайный лес и логистическую регрессию. По итогу исследования нашли наилучшую модель - случайный лес, где смогли добится accuracy = 0.821 на валидационной сборке. Проверили её на тестовых данных и получили результат 0.829. Сравнили модель со случайной и убедились в адекватности случайного леса. Задача стояла получить модель с accuracy больше 0.75 чего мы смогли добится."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1692,
    "start_time": "2022-09-30T12:31:30.056Z"
   },
   {
    "duration": 151,
    "start_time": "2022-09-30T12:31:31.750Z"
   },
   {
    "duration": 15,
    "start_time": "2022-09-30T12:31:31.903Z"
   },
   {
    "duration": 21,
    "start_time": "2022-09-30T12:31:31.921Z"
   },
   {
    "duration": 4,
    "start_time": "2022-09-30T12:31:31.944Z"
   },
   {
    "duration": 9,
    "start_time": "2022-09-30T12:31:31.949Z"
   },
   {
    "duration": 11,
    "start_time": "2022-09-30T12:31:31.960Z"
   },
   {
    "duration": 142549,
    "start_time": "2022-09-30T12:31:31.973Z"
   },
   {
    "duration": 30533,
    "start_time": "2022-09-30T12:33:54.524Z"
   },
   {
    "duration": 62,
    "start_time": "2022-09-30T12:34:25.060Z"
   },
   {
    "duration": 11,
    "start_time": "2022-09-30T12:34:25.124Z"
   },
   {
    "duration": 164,
    "start_time": "2022-09-30T12:34:25.136Z"
   },
   {
    "duration": 78,
    "start_time": "2022-09-30T12:34:25.302Z"
   },
   {
    "duration": 9,
    "start_time": "2022-09-30T12:34:25.382Z"
   },
   {
    "duration": 31,
    "start_time": "2022-09-30T12:34:25.393Z"
   },
   {
    "duration": 53,
    "start_time": "2022-09-30T12:34:25.426Z"
   },
   {
    "duration": 1056,
    "start_time": "2022-09-30T20:34:34.193Z"
   },
   {
    "duration": 147,
    "start_time": "2022-09-30T20:34:35.251Z"
   },
   {
    "duration": 13,
    "start_time": "2022-09-30T20:34:35.399Z"
   },
   {
    "duration": 24,
    "start_time": "2022-09-30T20:34:35.413Z"
   },
   {
    "duration": 8,
    "start_time": "2022-09-30T20:34:35.438Z"
   },
   {
    "duration": 5,
    "start_time": "2022-09-30T20:34:35.448Z"
   },
   {
    "duration": 9,
    "start_time": "2022-09-30T20:34:35.455Z"
   },
   {
    "duration": 6,
    "start_time": "2022-09-30T20:34:35.466Z"
   },
   {
    "duration": 15,
    "start_time": "2022-09-30T20:34:35.473Z"
   },
   {
    "duration": 8,
    "start_time": "2022-09-30T20:34:35.490Z"
   },
   {
    "duration": 10,
    "start_time": "2022-09-30T20:34:35.500Z"
   },
   {
    "duration": 10,
    "start_time": "2022-09-30T20:34:35.512Z"
   },
   {
    "duration": 5,
    "start_time": "2022-09-30T20:34:35.524Z"
   },
   {
    "duration": 131681,
    "start_time": "2022-09-30T20:34:35.530Z"
   },
   {
    "duration": 7,
    "start_time": "2022-09-30T20:36:47.213Z"
   },
   {
    "duration": 28594,
    "start_time": "2022-09-30T20:36:47.221Z"
   },
   {
    "duration": 3,
    "start_time": "2022-09-30T20:37:15.817Z"
   },
   {
    "duration": 13,
    "start_time": "2022-09-30T20:37:15.822Z"
   },
   {
    "duration": 142867,
    "start_time": "2022-09-30T20:37:15.837Z"
   },
   {
    "duration": 5,
    "start_time": "2022-09-30T20:39:38.706Z"
   },
   {
    "duration": 55,
    "start_time": "2022-09-30T20:39:38.713Z"
   },
   {
    "duration": 147,
    "start_time": "2022-09-30T20:39:38.770Z"
   },
   {
    "duration": 15,
    "start_time": "2022-09-30T20:39:38.919Z"
   },
   {
    "duration": 23,
    "start_time": "2022-09-30T20:39:38.936Z"
   },
   {
    "duration": 8,
    "start_time": "2022-09-30T20:39:38.961Z"
   },
   {
    "duration": 8,
    "start_time": "2022-09-30T20:39:38.971Z"
   },
   {
    "duration": 37,
    "start_time": "2022-09-30T20:39:38.981Z"
   },
   {
    "duration": 1117,
    "start_time": "2022-09-30T20:43:48.531Z"
   },
   {
    "duration": 52,
    "start_time": "2022-09-30T20:43:49.650Z"
   },
   {
    "duration": 10,
    "start_time": "2022-09-30T20:43:49.704Z"
   },
   {
    "duration": 19,
    "start_time": "2022-09-30T20:43:49.716Z"
   },
   {
    "duration": 8,
    "start_time": "2022-09-30T20:43:49.737Z"
   },
   {
    "duration": 3,
    "start_time": "2022-09-30T20:43:49.746Z"
   },
   {
    "duration": 8,
    "start_time": "2022-09-30T20:43:49.751Z"
   },
   {
    "duration": 4,
    "start_time": "2022-09-30T20:43:49.760Z"
   },
   {
    "duration": 7,
    "start_time": "2022-09-30T20:43:49.766Z"
   },
   {
    "duration": 6,
    "start_time": "2022-09-30T20:43:49.775Z"
   },
   {
    "duration": 6,
    "start_time": "2022-09-30T20:43:49.782Z"
   },
   {
    "duration": 7,
    "start_time": "2022-09-30T20:43:49.789Z"
   },
   {
    "duration": 5,
    "start_time": "2022-09-30T20:43:49.797Z"
   },
   {
    "duration": 131764,
    "start_time": "2022-09-30T20:43:49.804Z"
   },
   {
    "duration": 28718,
    "start_time": "2022-09-30T20:46:01.570Z"
   },
   {
    "duration": 4,
    "start_time": "2022-09-30T20:46:30.290Z"
   },
   {
    "duration": 22,
    "start_time": "2022-09-30T20:46:30.295Z"
   },
   {
    "duration": 142231,
    "start_time": "2022-09-30T20:46:30.318Z"
   },
   {
    "duration": 6,
    "start_time": "2022-09-30T20:48:52.550Z"
   },
   {
    "duration": 67,
    "start_time": "2022-09-30T20:48:52.558Z"
   },
   {
    "duration": 164,
    "start_time": "2022-09-30T20:48:52.626Z"
   },
   {
    "duration": 18,
    "start_time": "2022-09-30T20:48:52.792Z"
   },
   {
    "duration": 10,
    "start_time": "2022-09-30T20:48:52.811Z"
   },
   {
    "duration": 32,
    "start_time": "2022-09-30T20:48:52.822Z"
   },
   {
    "duration": 9,
    "start_time": "2022-09-30T20:48:52.857Z"
   },
   {
    "duration": 38,
    "start_time": "2022-09-30T20:48:52.868Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
